{
	"$schema": "https://opencode.ai/config.json",
	"theme": "catppuccin",
	"autoupdate": true,
	"provider": {
		"ollama": {
			"npm": "@ai-sdk/openai-compatible",
			"name": "Ollama (local)",
			"options": {
				"baseURL": "http://localhost:11434/v1"
			},
			"models": {
				"llama3.1:8b": {
					"name": "Llama 3 Instruct (local)",
				}
			}
		}
	},
  "model": "ollama/llama3.1:8b"
}
